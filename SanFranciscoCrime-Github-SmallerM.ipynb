{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6726f0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25580/2258284529.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpytz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Machine_Learning\\lib\\site-packages\\folium\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mbranca\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbranca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolormap\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mColorMap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinearColormap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStepColormap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m from branca.element import (\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Machine_Learning\\lib\\site-packages\\branca\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mbranca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolormap\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcolormap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbranca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Machine_Learning\\lib\\site-packages\\branca\\colormap.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m \u001b[0mlinear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_LinearColormaps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Machine_Learning\\lib\\site-packages\\branca\\colormap.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_schemes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_schemes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m         self._colormaps = {key: LinearColormap(val) for\n\u001b[0m\u001b[0;32m    433\u001b[0m                            key, val in _schemes.items()}\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_schemes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Machine_Learning\\lib\\site-packages\\branca\\colormap.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_schemes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_schemes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m         self._colormaps = {key: LinearColormap(val) for\n\u001b[0m\u001b[0;32m    433\u001b[0m                            key, val in _schemes.items()}\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_schemes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Machine_Learning\\lib\\site-packages\\branca\\colormap.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, colors, index, vmin, vmax, caption)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_parse_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrgba_floats_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Machine_Learning\\lib\\site-packages\\branca\\colormap.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_parse_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrgba_floats_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Machine_Learning\\lib\\site-packages\\branca\\colormap.py\u001b[0m in \u001b[0;36m_parse_color\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mcolor_tuple\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0m_is_hex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mcolor_tuple\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_hex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mcname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_cnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\Machine_Learning\\lib\\site-packages\\branca\\colormap.py\u001b[0m in \u001b[0;36m_parse_hex\u001b[1;34m(color_code)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_parse_hex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     return (int(color_code[1:3], 16),\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor_code\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             int(color_code[5:7], 16))\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.offsets import Hour, Minute, Second # ...\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "import itertools as it\n",
    "import pytz\n",
    "import numpy as np\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from folium.plugins import HeatMap, HeatMapWithTime, MarkerCluster\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering #kernel\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea0400",
   "metadata": {},
   "source": [
    "# DataSet概要\n",
    "## Data fields\n",
    "\n",
    "- 日付 -犯罪事件のタイムスタンプ\n",
    "- カテゴリ -犯罪事件のカテゴリ（train.csvのみ）。これは、予測するターゲット変数です。\n",
    "- 説明 -犯罪事件の詳細な説明（train.csvのみ）\n",
    "- DayOfWeek -曜日\n",
    "- PdDistrict-警察署地区の名前\n",
    "- 解決-犯罪事件がどのように解決されたか（train.csvのみ）\n",
    "- 住所-犯罪事件のおおよその 住所\n",
    "- X-経度\n",
    "- Y-緯度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3e8646",
   "metadata": {},
   "source": [
    "# First EDA  [Exploratory Data Analysis]\n",
    "- データを俯瞰的に見る。csvの内部状況の確認(columns,null,mean,std)\n",
    "- 以下から簡単にわかる事\n",
    "    1. タイムスタンプが存在し、それがカテゴリ化されてもいる。\n",
    "    2. タイムスタンプに対して曜日がカテゴライズされている。\n",
    "    3. タイムスタンプは犯罪発生日であるのでロケーションがカテゴライズされている。\n",
    "    4. ロケーションに対してX,Yは緯度経度であると推測できる。(これは推測せずともデータセットの説明に記述がある、しかしこれが何かを推測する事も大事。推測の過程で新たなFEを発見する可能性がある)\n",
    "    5. X,YはColumnsとして分かりにくいという場合にはLongitude, latitudeに名前を変えるという事も行う。(Lon,Latでも可)\n",
    "        - ライブラリによっては、緯度経度を渡す位置が逆になる事もあるのでライブラリを確認する。\n",
    "- 可能であると思われる可視化\n",
    "    1. 通常の可視化(Visualization)プロット\n",
    "    2. 地図を可視化し、犯罪がどの地区でよく発生しているのかを可視化できる\n",
    "    3. 何故その地区で犯罪発生件数が多いのか、SanFranciscoの別のデータ(店舗、居住区画、居住区画住宅価格、種族別居住有無し)と併用して様々な見解を得る事が出来る。\n",
    "    4. 犯罪発生率とGDP, 進学率, 過去のSingle世帯の多さ, 産業の発生・発展におけるタイムスタンプ的犯罪発生率の増減, サンフランシスコ全体の物価指数の伸び, 都市開発のタイムスタンプ, サンフランシスコの居住者の増減,　等のデータセットと組み合わせを行い、様々な知見が得られる。これは犯罪は増減する理由を根本的に説明する起源現象の解明に当たるであろうから、これそのものが該当する他の州の基礎コホートとしても成立する可能性がある(その場合、産業の発生発展は除外するべきであると推理する、これは州によって変化するからである)。\n",
    "- 可能であると思われる変換\n",
    "    1. 階層型カテゴライズ\n",
    "    2. クラスター変換作成、階層型クラスターの作成\n",
    "    3. 分布が正規分布に準じていない場合Box-Cox変換を使用した正規分布への変換\n",
    "    4. (変換後or無変換)正規分布を使用したガウス混合クラスタリング解析\n",
    "    5. PCAを使用して分散を維持したまま次元削減を行い、クラスタリングを可視化する。\n",
    "        - 可視化はあくまで知見を得る為に使用する、知見を得る事によってFeatureEnginieringの精度を上げる等の方法論的解釈を可視化によって行う。\n",
    "- 別Notebookでの論理哲学的事象発生探究の項から抜粋\n",
    "    - ある事象の発生はその事象が帰結した結果の付随する事象の総和である。これは何故その事象が発生するのか、というのを論理的に解説する物である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd22f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/JupyterNotebook/SanFranciscoCrimeDataset/train.csv')\n",
    "test = pd.read_csv('D:/JupyterNotebook/SanFranciscoCrimeDataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0030b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730594d8",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3).style.background_gradient(cmap='mako_r', text_color_threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d6f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().style.background_gradient(cmap='mako_r', text_color_threshold=0.02) # この記述統計量はあまり意味が無い、XとYは経度緯度を表している。testも同様"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7082a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a221b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060a72a7",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f933663",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(3).style.background_gradient(cmap='rocket', text_color_threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe().style.background_gradient(cmap='mako_r', text_color_threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed35d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7112dbf",
   "metadata": {},
   "source": [
    "-----------\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8945210",
   "metadata": {},
   "source": [
    "## unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db57659",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3).style.background_gradient(cmap='mako_r', text_color_threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fc29a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['PdDistrict'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92611a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Resolution'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d6a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Category'].unique() # この特徴量が予測子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04db01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['DayOfWeek'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ed28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Address'].unique(), len(train['Address'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d89a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train['Descript'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ca6fe",
   "metadata": {},
   "source": [
    "--------\n",
    "# Visualization\n",
    "1. DayOfWeekに対してCategoryの可視化、どの週が最も犯罪発生率が高いか。\n",
    "2. CategoryのHistgram\n",
    "3. PdDistrictのHistgram,つまりどの署が最も対応した数が多いか。\n",
    "4. タイムスタンプに対しての犯罪発生率の増減、季節性の視認。\n",
    "5. タイムスタンプの年毎の犯罪増減率と、その関係性を示す人流、GDP等の社会動態経済動態の知見。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization_crime(value, tight=False):\n",
    "    with plt.style.context('fivethirtyeight'):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(19, 6))\n",
    "        sns.histplot(x=value, data=train, kde=True, palette='rocket', ax=ax)\n",
    "        ax.tick_params(axis='x', rotation=90)\n",
    "        if tight == True:\n",
    "            fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc6199c",
   "metadata": {},
   "source": [
    "### Category Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcba15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_crime('Category', tight=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb55e7",
   "metadata": {},
   "source": [
    "### DayOfWeek Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d2deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_crime('DayOfWeek')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178c0050",
   "metadata": {},
   "source": [
    "### PdDistrict Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cbc9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_crime('PdDistrict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d11785",
   "metadata": {},
   "source": [
    "### Resolution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80973c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_crime('Resolution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfc951a",
   "metadata": {},
   "source": [
    "### Latitude Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_crime('X')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff5e8ae",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679eb3b9",
   "metadata": {},
   "source": [
    "## Seaborn ColorPalette\n",
    "[color_palette_Library](https://seaborn.pydata.org/generated/seaborn.color_palette.html#seaborn.color_palette)\n",
    "\n",
    "-------\n",
    "\n",
    "- 緯度経度情報が存在するので散布図として可視化する。\n",
    "    - こうする事によって散布図の形が街の形を表示する。これは件数が増えれば増える程視覚的に明確になる。\n",
    "    - ここでわかる事は、データのLatitude, Longitudeが座標を明確に示しており、正確であるという事が分かる。可視化せずにLatitude, Longitudeを使用するのは経験上危険である。\n",
    "    - 何処でどのようなCrimeが発生しているのかが一目瞭然になる。以下の散布図は250000/ALLを元に表示している、これはデータが実際の緯度経度であるのかを明確にするために行っている。\n",
    "        - 条件指定を行って特定のCrimeのみを表示させる事も可能。これは下記のFolium参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51759015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 街の形が視覚的に見えてくる。\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(19, 19))\n",
    "    sns.scatterplot(data=train.iloc[:250000], x='X', y='Y', alpha=0.6, palette='rocket', hue='Category', size='Category') # 878049 \n",
    "    plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a1fbc",
   "metadata": {},
   "source": [
    "- DayOfWeekによって細分化したデータ。データ数が多いので少しわかりにくいが、週末にかけて左寄りの形状を持つ。\n",
    "- これらの問題は全てfoliumで解決する。これはあくまでも実装前テスト表示に過ぎない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(19, 19))\n",
    "    sns.scatterplot(data=train.iloc[:50000], x='X', y='Y', alpha=0.6, palette='flare', hue='DayOfWeek',\n",
    "                    size='DayOfWeek', sizes=(20, 200), markers=True) # 878049 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a70e93",
   "metadata": {},
   "source": [
    "----\n",
    "# 1. Folium \n",
    ">2.では年間データの推移、クラスター化によるAnimation表示をFoliumで実装している。\n",
    "[Foliumライブラリ](https://python-visualization.github.io/folium/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe9801b",
   "metadata": {},
   "source": [
    "- 関数化\n",
    "- pandas queryを使用して高速化をはかりつつ(実際にはNumexpr)複数の条件によってデータのHeatmap表示を行えるようにしている。\n",
    "    - queryによって取得したASSAULTはダウンタウン、チャイナタウン周辺に集中している事がわかる。ベイエリアでも比較的多いのには集団が集まりやすい傾向にあるからであると推測できる。\n",
    "    - 集団がつまればCrimeに発展する確率が上がるのは以下のEDAで明確になるので以下参照。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_heat_map(query, location=[37.774599, -122.425892]):\n",
    "    train_query = train.query(query).loc[:, ['Y', 'X']]\n",
    "    if train_query.shape[0] == 0:\n",
    "        print('Either the query is failing or there is no data itself.')\n",
    "    m = folium.Map(location=location, zoom_start=13, tiles='CartoDB dark_matter') # HeatmapPlot-best-tiles : cartodbdark_matter\n",
    "    train_query_geo_list = train_query.values.tolist()\n",
    "    HeatMap(train_query_geo_list, blur=2, radius=3).add_to(m)\n",
    "    #m.save('SanFrancisco-Crime-geo.html') # add to variable string\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf213af",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_heat_map(\"Category=='ASSAULT' & Resolution=='ARREST, BOOKED'\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e907e",
   "metadata": {},
   "source": [
    "---------\n",
    "---------\n",
    "# タイムスタンプ操作\n",
    "1. indexをDates使用して読み込む場合\n",
    "2. DatesをTimestampとして読み込みを行い、Timestampのデータを分割変換する。分秒単位までは必要はあまりないと思われるが、時単位まで単体化する事によって有効なlineplotを行えると推測できる。これによって、効果的な第三者への視覚化が行える。例：.count()の統計量を利用して何時が最も犯罪率が多いか、等。\n",
    "3. 時系列データが存在する場合、積極的に時系列に変換して使用するのがベストプラクティス"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c171c2b7",
   "metadata": {},
   "source": [
    "# 1. indexをTimestampとして読み込む。\n",
    "- どのような変換が考えられるか。\n",
    "- 実際にこのデータをPre-Processingとして使用する訳ではない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce2910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamp = pd.read_csv('D:/JupyterNotebook/SanFranciscoCrimeDataset/train.csv', parse_dates=True, index_col='Dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e73259",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamp.loc['2015-05-13'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamp.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e24929",
   "metadata": {},
   "source": [
    "- 文字列は統計処理されない。これは緯度経度の各平均になっており、この平均をFoliumの基礎map-locationに使用する事も出来る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamp.loc['2015'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb78ab2",
   "metadata": {},
   "source": [
    "- 2015年のデータは途中までの期間しかないのか？それとも犯罪が減少する要因がアメリカ、特にサンフランシスコであったのか？という事を推理する。\n",
    "    - これは実際にはデータが特定期間までしかない事が減少要因、max(),min()等で確認できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b80eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamp.loc['2015'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928dcaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timestamp.loc['2013'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c166154",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = train_timestamp.groupby(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c968cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.count().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da1836",
   "metadata": {},
   "source": [
    "# 2. DatesはColumnsのままtimestampとして読み込む。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc01c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plot = pd.read_csv('D:/JupyterNotebook/SanFranciscoCrimeDataset/train.csv', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefb39bf",
   "metadata": {},
   "source": [
    "- info(),describe()は上記で実行済みなのでこのlineでは実行しない。\n",
    "- 以下では重複している行がどれだけ存在しているかを可視化、削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b971b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plot.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a28278",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "# シグマクリップ SigmaClip\n",
    "- シグマクリップを使用して外れ値の除去を行う。間違っている日付等(32日等)を一括で削除可能な方法。\n",
    "- 最後の行はサンプル平均のロバスト推定を使用している、0.74はガウス分布の四分位範囲から得られる値。ここでは実際の構文は記述しない。\n",
    "- queryを使用して高速化を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11cf417",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_c = pd.DataFrame(train_plot['Category'].value_counts(normalize=True))\n",
    "frequency_c.reset_index(inplace=True)\n",
    "frequency_c.rename({'index': 'Category', 'Category': 'Freq'}, axis=1, inplace=True)\n",
    "frequency_c['Cumsum_Freq'] = frequency_c['Freq'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06092095",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_c = frequency_c.set_index('Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_quantiles = np.percentile(frequency_c['Cumsum_Freq'], [25, 50, 75]) # array([0.84974358, 0.96996523, 0.99674847])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fb0180",
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = freq_quantiles[1] # 0.9699652297309147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b6f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.74 * (freq_quantiles[2] - freq_quantiles[0]) # 0.10878362141520569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0292f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_freq = frequency_c.query(\"(Cumsum_Freq > @qt - 5 * @sigma) & (Cumsum_Freq < @qt + 5 * @sigma)\") # Cumsum_Freq is Data_Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_freq.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad45ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_freq_list = list(query_freq['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8783bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_freq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e53ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sigma = train.loc[train['Category'].isin(query_freq_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9560c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sigma.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sigma['Dates'] = pd.to_datetime(train_sigma['Dates']) # Not Copy is SettingCopyWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda39315",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Dates'] = pd.to_datetime(test['Dates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf1a21",
   "metadata": {},
   "source": [
    "--------\n",
    "--------\n",
    "# Second EDA\n",
    "- 上記で得られた知見や、データ処理の結果を使用してより細分化したEDAを実行し、知見を得、第三者へのプレゼンテーションEDA資料の１つとする。\n",
    "- 各可視化の説明詳細はある程度省く。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e637cd1",
   "metadata": {},
   "source": [
    "# どのCrimeが最も多いか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e9a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(19, 19))\n",
    "    sns.countplot(y='Category', data=train_sigma, order=train_sigma['Category'].value_counts().index,  palette='rocket')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    #ax.set_xticklabels(ax.get_xticklabels(), rotation=60, ha=\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d99555",
   "metadata": {},
   "source": [
    "- 警察署別によってどの事件への対応が最も多いか？\n",
    "    - これは地図上に警察署をロケーションポイントとして表示させる事によってより明確に出来る。\n",
    "    - 余談：MISSION署は非常に危険なようだ、、。DRUGに関してはTENDERLOINが最も多い、これは有名な話でテンダーロインには観光に行くなというのは定説。他国を批判する気はないのだが、テンダーロインはサンフランシスコの中でもかなり治安が悪い事で有名。ASSAULTも同様に多い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab_train = pd.crosstab(train_sigma['Category'], train_sigma['PdDistrict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4be3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab_train.style.background_gradient(cmap='mako_r', text_color_threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2b7641",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_sigma_list = cross_tab_train.stack().reset_index().rename(columns= {0:'value'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a94de",
   "metadata": {},
   "source": [
    "- 数値的可視化からバープロットによる視覚的可視化を行う。両方行う事も重要、知見の多様化を行える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c43ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    fig, ax = plt.subplots(1, 1, figsize= (15,10))\n",
    "    sns.barplot(x=stack_sigma_list['PdDistrict'], y=stack_sigma_list['value'], hue=stack_sigma_list['Category'],  palette='rocket')\n",
    "    ax.set_title('Categories Count per District')\n",
    "    plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd8187",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "- 0.8ベースで表示した場合以下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ed87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_c = pd.DataFrame(train_plot['Category'].value_counts(normalize=True))\n",
    "frequency_c.reset_index(inplace=True)\n",
    "frequency_c.rename({'index': 'Category', 'Category': 'Freq'}, axis=1, inplace=True)\n",
    "frequency_c['Cumsum_Freq'] = frequency_c['Freq'].cumsum()\n",
    "frequency_50_list = list(frequency_c.loc[frequency_c['Cumsum_Freq'] < 0.8, 'Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aa37c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_50_list = train.loc[train['Category'].isin(frequency_50_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be19be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_50_list['Dates'] = pd.to_datetime(train_50_list['Dates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c09e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(19, 19))\n",
    "    sns.countplot(y='Category', data=train_50_list, order=train_50_list['Category'].value_counts().index,  palette='rocket')\n",
    "    ax.tick_params(axis='x', rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac7c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_50_list = pd.crosstab(train_50_list['Category'], train_50_list['PdDistrict'])\n",
    "ct_50_list.style.background_gradient(cmap='mako_r', text_color_threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5da64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_50_list = ct_50_list.stack().reset_index().rename(columns= {0:'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d1e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    fig, ax = plt.subplots(1, 1, figsize= (15,10))\n",
    "    sns.barplot(x=stack_50_list['PdDistrict'], y=stack_50_list['value'], hue=stack_50_list['Category'], palette='rocket')\n",
    "    ax.set_title('Categories Count per District')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9959d6f",
   "metadata": {},
   "source": [
    "---------\n",
    "---------\n",
    "# Pre-Processing & Feature Enginiering\n",
    "- 上記で得られた知見を利用してデータの変換と特徴量エンジニアリングを行う。\n",
    "- 日時変換には国土交通省指定の時間分割表を参照している。\n",
    "- 解説、に該当する特徴量に関しては、これ以降のPipelineで削除する。これは変換は非常に難しい事と（NLPを利用等）testセットにこの特徴量が存在していないので、解説をテストセットに対して追加するのはベストプラクティスとはなりえないであろうという事。ただし、正確な予測をする場合、完全削除する事は悪手でしかない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d1329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sigma.shape, train_50_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_group(date):\n",
    "    \n",
    "    date['Date'] = date['Dates'].dt.date\n",
    "    date['Year'] = date['Dates'].dt.year\n",
    "    date['Month'] = date['Dates'].dt.month\n",
    "    date[\"Day\"] = date[\"Dates\"].dt.day\n",
    "    date[\"Hour\"] = date[\"Dates\"].dt.hour\n",
    "    date[\"Minute\"] = date[\"Dates\"].dt.minute\n",
    "    date[\"Second\"] = date[\"Dates\"].dt.second\n",
    "    \n",
    "    ca = calendar()\n",
    "    holidays = ca.holidays(start=date['Dates'].min(), end=date['Dates'].max())\n",
    "    date['Holiday']= date['Dates'].dt.date.astype('datetime64').isin(holidays)\n",
    "    # Week_replace\n",
    "    week_mapping = {'Saturday': 5, 'Sunday': 6, 'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4}\n",
    "    date['Week_Mapping'] = date['DayOfWeek'].map(week_mapping)\n",
    "    \n",
    "    # https://www.jma.go.jp/jma/kishou/know/yougo_hp/saibun.html 国土交通省：気象庁[定義区分] time scale\n",
    "    def hour_Segmentation(x):\n",
    "        if x >= 3 and x < 9:\n",
    "            return 0\n",
    "        elif x >= 9 and x < 15:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "        \n",
    "    def morning_Or_Afternoon(x): # np.where\n",
    "        if x >= 0 and x > 12:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    def daytime_Or_Nighttime(x): # np.where\n",
    "        if x >= 9 and x > 18:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    def default_Work_Time_Hours(x): # np.where\n",
    "        return 8 <= x <= 18\n",
    "    \n",
    "    def weekday_and_ends(x):\n",
    "        return np.where(x < 5, 'Weekday', 'Weekend')\n",
    "    \n",
    "    # Q1:1 , Q2:2, Q3:3, Q4:4\n",
    "    def quarter(x):\n",
    "        if x >= 1 and x <= 3:\n",
    "            return 1\n",
    "        elif x > 3 and x <= 6:\n",
    "            return 2\n",
    "        elif x > 6 and x <= 9:\n",
    "            return 3\n",
    "        elif x > 9 and x <= 12:\n",
    "            return 4\n",
    "    \n",
    "    # T1:1, T2:2, T3:3\n",
    "    def month_sep(x):\n",
    "        if x >= 1 and x < 10:\n",
    "            return 1\n",
    "        elif x >= 10 and x < 20:\n",
    "            return 2\n",
    "        elif x >= 20 and x <= 31:\n",
    "            return 3\n",
    "    \n",
    "    def street_type(x):\n",
    "        street_list = x.split(' ')\n",
    "        for index in range(len(street_list)):\n",
    "            fo_list = street_list[index]\n",
    "            if len(fo_list) == 2 and fo_list not in ['OF', 'US', 'LA', 'of']:\n",
    "                return fo_list\n",
    "        \n",
    "    date['Street_type'] = date['Address'].apply(street_type)\n",
    "   \n",
    "    date['HourGroup'] = date[\"Hour\"].apply(hour_Segmentation)\n",
    "    date['MAGroup'] = date['Hour'].apply(morning_Or_Afternoon)\n",
    "    date['DNGroup'] = date['Hour'].apply(daytime_Or_Nighttime)\n",
    "    date['DworkGroup'] = date['Hour'].apply(default_Work_Time_Hours)\n",
    "    date['Week_cat'] = date['Week_Mapping'].apply(weekday_and_ends)\n",
    "    date['Month_quarter'] = date['Month'].apply(quarter)\n",
    "    date['Month_sep'] = date['Day'].apply(month_sep)\n",
    "    \n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e483d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sigma_1 = train_sigma.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_50_list_1 = train_sigma.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aea157",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group = time_group(train_sigma_1) # Main_train_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group = time_group(test) # Main_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954737bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group.shape, test_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda446a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group_1 = time_group(train_50_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950da579",
   "metadata": {},
   "source": [
    "------\n",
    "### 変換後のデータを確認する。\n",
    "- 明らかに2015年のデータが少ない、これは上記でも記述した通りデータが途中期間までしか存在していない為"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66895449",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_data = pd.DataFrame(train_group.groupby('Year')['Category'].count())\n",
    "year_data_1 = pd.DataFrame(train_group_1.groupby('Year')['Category'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed31353",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8322b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_data.T.style.background_gradient(cmap='mako_r', text_color_threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227db674",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_data.drop(12, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a035ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_data.T.style.background_gradient(cmap='mako_r', text_color_threshold=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5ea3e",
   "metadata": {},
   "source": [
    "--------\n",
    "--------\n",
    "# 新特徴量による可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52fe716",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_vs_cate = train_group.groupby(['Category', 'HourGroup'], as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f1f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_vs_cate.style.background_gradient(cmap='mako_r', text_color_threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f912be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_vs_cate_pv = hour_vs_cate.pivot(index='HourGroup', columns='Category', values='Dates') #.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a86d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_vs_cate_pv.style.background_gradient(cmap='mako_r', text_color_threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(50, 5)) \n",
    "sns.heatmap(hour_vs_cate_pv.apply(lambda x:x/sum(x),axis=0), square=True, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    de_time = train_group.groupby([train_group.Week_cat, train_group.Hour])['Category'].count()\n",
    "    de_time.plot(figsize=(19, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5631cb38",
   "metadata": {},
   "source": [
    "- Weekend,dayでのCrime発生数\n",
    "- 12時にCrimeが発生する確率が上昇する。これは集団を形成する為に、そのような状況が必然的に発生しうる状況が作成されるという事でもある。\n",
    "- 2番目の可視化でも12時にCrime発生が一時的に上昇する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a18d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    de_time = train_group.groupby([train_group.Week_cat, train_group.Hour])['Category'].count()\n",
    "    de_time.loc['Weekday'].plot(figsize=(19, 6), label='Week_Day')\n",
    "    de_time.loc['Weekend'].plot(figsize=(19, 6), label='Week_End')\n",
    "    plt.title('Week, Day or End Crimes')\n",
    "    plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66986dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    pt = pd.pivot_table(train_group.loc[:, ['Hour', 'Category']], index=\"Hour\", columns=\"Category\", aggfunc=len, fill_value=0)\n",
    "    pt.plot(figsize=(30,10))\n",
    "    plt.title('Hour Crimes')\n",
    "    plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')\n",
    "    #plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693c9c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    pt = pd.pivot_table(train_group.loc[:, ['Year', 'Category']], index='Year', columns='Category', aggfunc=len, fill_value=0)\n",
    "    pt.plot(figsize=(30,10))\n",
    "    #plt.gca().set_xticklabels(['2010', '2011', '2012', '2013', '2014', '2015'])\n",
    "    plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14629b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    fig, ax = plt.subplots(figsize=(30, 10))\n",
    "    ax = sns.lineplot(x=year_data['Year'], y=year_data['Category'])\n",
    "    ax.set_title('Year Crimes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2413353",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    pt = pd.pivot_table(train_group.loc[:, ['Month', 'Category']], index='Month', columns='Category', aggfunc=len, fill_value=0)\n",
    "    pt.plot(figsize=(30,10))\n",
    "    plt.legend(bbox_to_anchor=(1.0, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f68a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = train_group.loc[:, ['Year', 'Category']].reset_index().merge(train_group.loc[:, ['Y', 'X']].reset_index(), on=['index']).set_index('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cff109",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_g = train_group.groupby([\"Category\", \"Year\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_g.unstack()['Dates'].style.background_gradient(cmap='mako_r', text_color_threshold=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd0dd65",
   "metadata": {},
   "source": [
    "-----\n",
    "-----\n",
    "# 2. Folium\n",
    "- Foliumによる動的な可視化を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = list(np.sort(train_group['Year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cec695",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_query_move = train_group.query(\"Category=='ASSAULT'\").loc[:, ['Y', 'X', 'Year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42bb52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_query_move = train_query_move.set_index('Year', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d339410",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_11 = np.sort(train_query_move.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc465af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_move_list = [train_query_move.loc[i].values.tolist() for i in np.sort(train_query_move.index.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_query = train.query(\"Category=='ASSAULT' & Resolution=='ARREST, BOOKED'\").loc[: ,['Y','X']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb28010",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_query_geo_list = train_query.values.tolist() # default feat map array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb14f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_time = np.sort(train_query_move.index.unique()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f5cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのソートとindexの追加、そしてヒートマップサイズの調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3833e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用するかわからないが一応作成したロケーションのリスト基本はdict型を使用するのが効率的にもよい。\n",
    "'''\n",
    "down_town = [[37.77493, -122.419416]]\n",
    "union_square = [[37.786163522, -122.404498382]]\n",
    "fishermans_wharf = [[37.80499678, -122.409331696]]\n",
    "china_town = [[37.790163506, -122.404331716]]\n",
    "soma = [[37.777311, -122.411083]]\n",
    "oak_street = [[37.77412, -122.431384]]\n",
    "twin_peaks = [[37.751586275, -122.447721511]]\n",
    "southeast = [[37.7369444, -122.3941667]]\n",
    "bernal_heights = [[37.744385, -122.417046]]\n",
    "mission_district = [[37.76, -122.42]]\n",
    "noe_valley = [[37.7502, -122.4337]]\n",
    "haight_ashbury = [[37.770015, -122.446937]]\n",
    "presidio = [[37.798085, -122.466538]]\n",
    "'''\n",
    "\n",
    "sanfrancisco_location = {'down_town': [[37.77493, -122.419416]], 'union_square': [[37.786163522, -122.404498382]],\n",
    "                         'fishermans_wharf': [[37.80499678, -122.409331696]], 'china_town': [[37.790163506, -122.404331716]],\n",
    "                         'soma': [[37.777311, -122.411083]], 'oak_street': [[37.77412, -122.431384]],\n",
    "                         'twin_peaks': [[37.751586275, -122.447721511]], 'southeast': [[37.7369444, -122.3941667]],\n",
    "                         'bernal_heights': [[37.744385, -122.417046]], 'mission_district': [[37.76, -122.42]],\n",
    "                         'noe_valley': [[37.7502, -122.4337]], 'height_ashbury': [[37.770015, -122.446937]], 'presidio': [[37.798085, -122.466538]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_polygon(lat_lon):\n",
    "    '''lat_lonを基準としてgeographic quarter(NW, NE, SW, SE)を求める'''\n",
    "    sw, nw, se, ne = [(lat + py * pow(10, -3), lon + px * pow(10, -3)) for px, py in it.product([-1, 1], [-1, 1]) for lat, lon in lat_lon]\n",
    "    return [sw, se, ne, nw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_point(location):\n",
    "    '''LocationPointを一括で表示させる関数：辞書による変数'''\n",
    "    for location_name, lat_lon in location.items():\n",
    "        lat_lon_locate = geo_polygon(lat_lon)\n",
    "        folium.Polygon(locations=lat_lon_locate, color=\"red\", weight=1, fill=True, fill_opacity=0.1, popup=location_name).add_to(m)\n",
    "\n",
    "def location_point_1(location):\n",
    "    for location_name, lat_lon in location.items():\n",
    "        lat_lon_locate = geo_polygon(lat_lon)\n",
    "        folium.Polygon(locations=lat_lon_locate, color=\"red\", weight=1, fill=True, fill_opacity=0.1, popup=location_name).add_to(m_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4643ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[37.774599, -122.425892], zoom_start=13, tiles='CartoDB dark_matter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f431bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_point(sanfrancisco_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ffce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HeatMapWithTime(train_query_geo_list,auto_play=False,radius=40,max_opacity=1,gradient={0.1: 'blue', 0.25: 'lime', 0.5:'yellow',0.75: 'red'}).add_to(m)\n",
    "HeatMapWithTime(train_move_list, index=index_time, auto_play=False, radius=1 , max_opacity=1, gradient={0.1: 'blue', 0.25: 'lime', 0.5:'yellow',0.75: 'red'}).add_to(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f84817",
   "metadata": {},
   "source": [
    "## 2003-2015年までのASSAULTの散布図\n",
    "- 再生ボタンで動的に表示されます。fpsはデフォルトの10を使用しているが、スライドバーを上げる事によって上げられます。\n",
    "- 赤枠はロケーションポイントで、クリックするとロケーション名が表示されます。赤枠にしている理由はこのような表示が可能という事を見せているだけです。本来ピンが最も効果的であると思われます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb1d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a378a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_1 = folium.Map(location=[37.774599, -122.425892], zoom_start=13, tiles='CartoDB dark_matter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda20986",
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_cluster = MarkerCluster().add_to(m_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_point_1(sanfrancisco_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7648972",
   "metadata": {},
   "outputs": [],
   "source": [
    "for point in range(0, len(train_query_geo_list)):\n",
    "    folium.Marker(train_query_geo_list[point], popup='A').add_to(marker_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007d6ac9",
   "metadata": {},
   "source": [
    "### 2003-2015年までのASSULTのクラスタリング表示\n",
    "- マップをスクロールする事によっても、対象の区画をクリックする事でもクラスタを可視化する事が出来ます。緯度経度が正確に記録されている為、最小単位までスクロールダウンした時、どの位置で事件が起きているのか明確にピンで見る事が出来ます。作成したPCの性能上の問題で、ピンには全て'A'と表示されていますが、事件の内容そのものを表示させる事も可能、最小単位のマーカーにはそれが何であるのかを表示させられるpopupが存在するので、そこにCrimeの詳細を表示させられる。\n",
    "- これにはlat_lonの管理にIDを連結させ、その連結項目からCrimeの詳細を取り出してpopupで表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3995965",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df300fd8",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "## 各Crimeが週のうち何時起きているのかを可視化する。\n",
    "- これによって事件の性質や、その事件の背景がより明確に知見としての推理を得られる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_map = {'Saturday': 0, 'Sunday': 1, 'Monday': 2, 'Tuesday': 3, 'Wednesday': 4, 'Thursday': 5, 'Friday': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935fcb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dayOfWeek_plot(data, string='ASSAULT'):\n",
    "    with plt.style.context('fivethirtyeight'):\n",
    "        week_data = pd.DataFrame(data[data['Category'] == string].groupby(by=['DayOfWeek'])['Category'].count()).reset_index()\n",
    "        week_data['SortedDayOfWeek'] = week_data['DayOfWeek'].map(sorted_map)\n",
    "        week_data = week_data.sort_values('SortedDayOfWeek').drop('SortedDayOfWeek', axis=1)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize = (19, 6))\n",
    "        ax = sns.lineplot(x=week_data['DayOfWeek'], y=week_data['Category'])\n",
    "        ax.set_title('{} Crimes. Week'.format(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d329fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dayOfWeek_plot(train_group, 'ASSAULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac0427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train_group['Category'].unique()); # test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e4df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add def dayOfWeel_plot\n",
    "for string in list(train_group['Category'].unique()):\n",
    "    dayOfWeek_plot(train_group, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd33819",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(19, 6))\n",
    "    sns.kdeplot(train_group.groupby('Date').count().iloc[:, 1], shade=True, palette=['#682F2F'])\n",
    "    plt.xlabel('Incidents')\n",
    "    plt.ylabel('Density')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c583f5cf",
   "metadata": {},
   "source": [
    "### Holiday "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d84bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_holiday_cat = pd.crosstab(train_group['Category'], train_group['Holiday'])\n",
    "ct_holiday_cat.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53265e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = ct_holiday_cat.stack().reset_index().rename(columns={0:'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.loc[stacked['Holiday'] == False, 'value'] /= train_group.loc[train_group['Holiday'] == False, 'Holiday'].count()\n",
    "stacked.loc[stacked['Holiday'] == True, 'value'] /= train_group.loc[train_group['Holiday'] == True, 'Holiday'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ecd40c",
   "metadata": {},
   "source": [
    "- Holiday　Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f09bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (19, 6))\n",
    "    bar = sns.barplot(x=stacked['Category'], y=stacked['value'], hue=stacked['Holiday'], palette=['#682F2F', '#F3AB60'])\n",
    "    bar.set_title('Proportions of crimes during regular days vs holidays')\n",
    "    ax.tick_params(axis='x', rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78cbc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_business_hrs_cat = pd.crosstab(train_group['Category'], train_group['DworkGroup'])\n",
    "ct_business_hrs_cat.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b7ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = ct_business_hrs_cat.stack().reset_index().rename(columns={0:'value'})\n",
    "stacked.loc[stacked['DworkGroup'] == False, 'value'] /= train_group.loc[train_group['DworkGroup'] == False, 'DworkGroup'].count()\n",
    "stacked.loc[stacked['DworkGroup'] == True, 'value'] /= train_group.loc[train_group['DworkGroup'] == True, 'DworkGroup'].count()\n",
    "stacked.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02e0cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (19, 6))\n",
    "    bar = sns.barplot(x=stacked['Category'], y=stacked['value'], hue=stacked['DworkGroup'], palette=['#682F2F', '#F3AB60'])\n",
    "    bar.set_title('Proportions of crimes during regular days vs holidays')\n",
    "    ax.tick_params(axis='x', rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774d02e",
   "metadata": {},
   "source": [
    "----------\n",
    "# TimeStamp の変換\n",
    "- 時系列データを営業日や四半期などの表示に切り替えてデータを推理する事も重要だが、これは変換のみにしておき省く。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea36af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30fb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group_2 = train_group.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group_2.set_index('Dates', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group_2.loc['2014'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_d = pd.to_datetime(train_group_2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d84e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group_freq_d = pd.DataFrame(train_group_2, index=freq_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group_2.to_period('Q-DEC').head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b371fa0",
   "metadata": {},
   "source": [
    "------\n",
    "------\n",
    "## Main-Pre-Process-Pipeline\n",
    "\n",
    "- 次の処理で必要なのはカテゴリ化を正確に行える処理。\n",
    "    - Address, Resolusion, Descriptは一意な値が正確ではない。これらの処理を行う必要がある。\n",
    "    \n",
    "    - Address : 済(street_type)\n",
    "        - 更にそのストリートがどの区画にあるのかという特徴の追加も可能であると思われる(以下では行っていない)\n",
    "       \n",
    "- Category : target\n",
    "- Delete Columns : Address, Dates\n",
    "\n",
    "- モデルに渡しているpipelineではStreetTypeを削除したPipelineを使用している、これはPC環境によってはモデルの訓練に時間がかかる為、桁数の指定を行った際にカテゴリが合わなくなる状況が発生するのを避ける為に行っている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6ed051",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_group.drop(['Dates', 'Descript', 'Resolution', 'Address', 'Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c536446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group.drop(['Id','Dates', 'Address', 'Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca3874",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_group.drop('Category', axis=1)\n",
    "y = train_group['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786bb6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd1783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = X.drop(['DayOfWeek', 'PdDistrict', 'DworkGroup', 'Week_cat', 'Holiday', 'Street_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f242b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_attribs = list(data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_attribs = ['DayOfWeek', 'PdDistrict', 'DworkGroup', 'Week_cat', 'Holiday', 'Street_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34751b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_pipeline = Pipeline([\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "main_pipeline = ColumnTransformer([\n",
    "    (\"number\", number_pipeline, number_attribs),\n",
    "    (\"categorie\", OneHotEncoder(), category_attribs),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f38a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42efe0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3fcd57",
   "metadata": {},
   "source": [
    "-----\n",
    "# Default Transform\n",
    "\n",
    "- 本来のPipeline Transform\n",
    "- モデルの訓練時間の都合上、このNotebookではこれを使用していない。\n",
    "- Clusteringは含めずに変換している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9143381",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_x = main_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0795f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_test = main_pipeline.transform(test_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(main_x, data_labels, test_size=0.25, stratify=data_labels, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc07876",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5350563f",
   "metadata": {},
   "source": [
    "# Githubの仕様上FileUploadは1file25MBが上限なので、以下のクラスタリング以降のPipelineは事前実行していません。Binderか、自環境で表示させてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bc7b91",
   "metadata": {},
   "source": [
    "------\n",
    "------\n",
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a057b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error:変数格納で改善、連続的にshowする事でこのエラーは発生しない : 変数に格納しない場合、一つのlineにshow()までを格納する。\n",
    "# https://stackoverflow.com/questions/69285993/kmeans-object-has-no-attribute-k\n",
    "model = KMeans(init='k-means++', n_init=10)\n",
    "visualizer = KElbowVisualizer(model, k=(1, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize = visualizer.fit(main_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2af95f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd39b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cluster_data = KMeans(n_clusters=visualizer.elbow_value_).fit_predict(main_x) # 6 or 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ac0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cluster_test = KMeans(n_clusters=visualizer.elbow_value_).fit_predict(main_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac450ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cluster = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52667f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cluster = test_group.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c8713",
   "metadata": {},
   "source": [
    "- 作成したクラスタを代入する。これを再度Transformする事になるが、Transform前にClusteringを行う方がよい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f647f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cluster['Cluster'] = main_cluster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484cc012",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cluster['Cluster'] = main_cluster_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914264e0",
   "metadata": {},
   "source": [
    "---------------\n",
    "## Second Cluster transform\n",
    "\n",
    "- Firstは実質的な最終Transformだが、index数が多すぎて通常のPC環境では処理に時間がかかるという問題が発生する。これを解決する為に、変換する前にindexの一部を削減する。この方法はベストではないむしろ悪手であるが、モデルを動かすという点では有益。これで得られる結果は正確ではないという事を理解しておく事が重要。\n",
    "- まず、変換に掛ける前のクラスターを代入したデータセットからデータの一部のみを取り出す。これは、.sample()でもよいように思う(ランダムで取り出せるので)\n",
    "- 取り出し前のデータセット数は50万あるので、これを10万以下にする必要があるように思う(これは調整でどうにかする。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e361be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test　cv=kfold　に使用する。GridSearchCV等に使われる、他のcvにも使用可能。\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "#kfold =StratifiedKFold(n_splits=5,shuffle=True,random_state=42)　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca999d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cluster.shape, X_cluster[:100000].shape # この状態でmodelに渡す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ccf3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上記の構文でもよいが、カテゴリ化する際のErrorを避ける為に、下記では.sample()を使用.(このNotebookでは使用していない。削除で対応している。)\n",
    "# 他にも、streetカテゴリが変換上全て含まれない場合が多いので、以下のモデルでは削除する。これも本来は削除してはならない特徴量で実環境では追加して変換をかける事: Street_type\n",
    "X_cluster.sample(10000);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a2e892",
   "metadata": {},
   "source": [
    "-----\n",
    "- 以下は本来は必要ない。これはモデルを円滑に実行させるための構文で、本来のベストプラクティスではない。モデルを動かす為以外で使用する場合は最悪の悪手である\n",
    "- Streetがカテゴリ化されるため、X_clusterのフルサンプルでなければカテゴリ数が足りないと言われる可能性があるが、これはベストプラクティスではないので何度か実行すれば全て含まれる。\n",
    "- 以下ではStreetを削除している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9de696",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cluster_test = X_cluster.drop('Street_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d84266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cluster_test = test_cluster.drop('Street_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff2d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = X.drop(['DayOfWeek', 'PdDistrict', 'DworkGroup', 'Week_cat', 'Holiday', 'Street_type'], axis=1)\n",
    "number_attribs = list(data_num)\n",
    "category_attribs = ['DayOfWeek', 'PdDistrict', 'DworkGroup', 'Week_cat', 'Holiday']\n",
    "\n",
    "number_pipeline = Pipeline([\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "main_pipeline = ColumnTransformer([\n",
    "    (\"number\", number_pipeline, number_attribs),\n",
    "    (\"categorie\", OneHotEncoder(), category_attribs),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e900a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_x_1 = main_pipeline.fit_transform(X_cluster_test.sample(50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57687271",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_test_1 = main_pipeline.transform(test_cluster_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ad0e14",
   "metadata": {},
   "source": [
    "-----\n",
    "# このNotebookで使用する、最終的な訓練セットと検証セット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faff1f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(main_x_1, data_labels[:50000], test_size=0.25, shuffle=True) # stratify=data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066f6336",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec3444e",
   "metadata": {},
   "source": [
    "--------\n",
    "# Model\n",
    "\n",
    "- GridSearchCV,RandomizedSearchCV,CV等はこのNotebookを作成した低スペック環境上使用していません。\n",
    "- 上記の通り、Modelのハイパーパラメータの調整は行っていないので性能はかなり低い。訓練の可視化も行っていないのでどのような状態になっているのかも視覚的にはわかりません。\n",
    "- Modelの訓練に関しては私の作成している別のNotebookを参照して下さい。\n",
    "\n",
    "- 最低限のModelの作成しか行っていない。\n",
    "- y_pred_gbでCategoryの予測が行われている。つまり、その事件が何であるかを予測しているという事、これは特徴量の性質を持つ事件が発生した場合、それが何であるかを予測して準備対応する備えが事前に可能という事でもある。事件が発生する確率も予測する事が可能。まるでトム・クルーズ主演のマイノリティリポート。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffbbd5d",
   "metadata": {},
   "source": [
    "# XGBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc80ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(use_label_encoder=True, metric='mlogloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa1ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70056ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision : {} / Recall : {}'.format(precision_score(y_val, y_pred_xgb, average='micro'), recall_score(y_val, y_pred_xgb, average='micro')))\n",
    "print(classification_report(y_val, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b3048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_val, y_pred_xgb))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(19, 19))\n",
    "disp.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10daffcd",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026c6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gb_model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100a3b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gb_model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3cea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gb_param_grid = {'learning_rate':[0.1, 0.01, 0.001], 'max_depth':[5, 10], 'n_estimators':[10, 100, 200, 300]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d51746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10. : stratify=data_labels\n",
    "#gb_s_model = GridSearchCV(gb_model, gb_param_grid, cv=10, scoring='accuracy')\n",
    "#gb_s_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2dbe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練セットとテストセットの数が多すぎるので訓練終了に時間がかなりかかる。これを許容時間内に(テスト結果に関わらず)終わらせるには、シャッフル時に一定の訓練セットとテストセットを取り出す\n",
    "gb_model = GradientBoostingClassifier(learning_rate=0.1, max_depth=5, n_estimators=5)\n",
    "%timeit gb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb87a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gb = gb_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5804550",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision : {} / Recall : {}'.format(precision_score(y_val, y_pred_gb, average='micro'), recall_score(y_val, y_pred_gb, average='micro')))\n",
    "print(classification_report(y_val, y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a08719",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_val, y_pred_gb))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(19, 19))\n",
    "disp.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8455be",
   "metadata": {},
   "source": [
    "--------\n",
    "# Other Models Creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444ef84e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine_Learning",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
